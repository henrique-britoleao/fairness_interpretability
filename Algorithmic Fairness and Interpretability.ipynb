{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_project.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-18e2a586aba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_project.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MonthRefunding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CreditAmount\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CreditDuration\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_project.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import json\n",
    "import seaborn as sns \n",
    "import warnings\n",
    "import shap\n",
    "import alibi\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_excel(\"data_project.xlsx\")\n",
    "df[\"MonthRefunding\"] = df[\"CreditAmount\"]/df[\"CreditDuration\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', \"r\") as f:\n",
    "    data = f.read()\n",
    "  \n",
    "      \n",
    "# reconstructing the data as a dictionary\n",
    "js = json.loads(data)\n",
    "\n",
    "#On remplace les données codées par du texte\n",
    "\n",
    "df = df.replace(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"CreditRisk (y)\").Age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age and credit risk\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# matplotlib histogram\n",
    "\n",
    "\n",
    "# seaborn histogram\n",
    "fig, ax = plt.subplots(figsize=(12,8), dpi=300)\n",
    "\n",
    "sns.distplot(df[df[\"CreditRisk (y)\"]==0]['Age'], hist=True, kde=True, \n",
    "             bins=int(180/5), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "# Add labels\n",
    "plt.title('Histogram of Age for risked credit people')\n",
    "plt.xlabel('Age(years)')\n",
    "plt.ylabel('Number of people');\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8), dpi=300)\n",
    "\n",
    "sns.distplot(df[df[\"CreditRisk (y)\"]==1]['Age'], hist=True, kde=True, \n",
    "             bins=int(180/5), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "# Add labels\n",
    "plt.title('Histogram of Age for not-risked credit people')\n",
    "plt.xlabel('Age(years)')\n",
    "plt.ylabel('Number of people');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2)\n",
    "\n",
    "df.groupby(\"EmploymentDuration\")[\"CreditRisk (y)\"].mean().sort_values(ascending=False).plot(kind=\"bar\", figsize=(12, 12), title=\"Risk credit rate according to employment duration\", ax=axes[1,1])\n",
    "df.groupby(\"CreditRisk (y)\")[\"CreditDuration\"].mean().plot(kind=\"bar\", figsize=(12, 12), title=\"Risk credit rate according to credit duration\", rot=0, ax=axes[0,1])\n",
    "df.groupby(\"CreditHistory\")[\"CreditRisk (y)\"].mean().sort_values(ascending=False).plot(kind=\"bar\", figsize=(12, 13), title=\"Credit risk according to purpose product\", ax=axes[1, 0])\n",
    "df.boxplot(\"CreditAmount\", ax=axes[0,0], by=\"CreditRisk (y)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Modelling with surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "Oe = OneHotEncoder()\n",
    "le = OrdinalEncoder()\n",
    "\n",
    "to_encode = ['CreditHistory', 'EmploymentDuration', 'Housing', 'Purpose', 'Savings']\n",
    "\n",
    "df[\"MonthRefunding\"] = df[\"CreditAmount\"]/df[\"CreditDuration\"]\n",
    "\n",
    "for col in to_encode:\n",
    "    df[col] = le.fit_transform(np.array(df[col]).reshape(-1, 1))\n",
    "\n",
    "X, y = df.drop([\"CreditRisk (y)\", \"y_hat\"], axis=1), df[\"CreditRisk (y)\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"The accuracy of the model is {:.2f}\".format(model.score(X_test, y_test)))\n",
    "print(\"The precision of the model is {:.2f}\".format(precision_score(y_pred, y_test)))\n",
    "print(\"The recall of the model is {:.2f}\".format(recall_score(y_pred, y_test)))\n",
    "print(\"The f1-score of the model is {:.2f}\".format(f1_score(y_pred, y_test)))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "# predict probabilities\n",
    "lr_probs = model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"ROC Curve of the Logistic Regression model\", fontsize=15)\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, label='Model', color=\"blue\")\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.DataFrame(model.coef_, columns=X.columns).T.sort_values(by=0,ascending=False).plot(kind=\"bar\", figsize=(12, 12), title=\"Feature importance of the surrogate model\", legend=False)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(np.round(p.get_height(), 2)), (p.get_x() * 1.05, p.get_height() * 1.005));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "X, y = df.drop([\"CreditRisk (y)\", \"y_hat\"], axis=1), df[\"CreditRisk (y)\"]\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The partial_dependence function returns the dependencies and the grid\n",
    "PDs, grid = partial_dependence(model, X, features = ['CreditDuration'], percentiles = [0,1])\n",
    "\n",
    "#The plot_partial_dependence function returns a plot, but can also be unpacked into dependencies and grids\n",
    "#plot_partial_dependence(model, X, features = ['CreditDuration'], percentiles = [0,1]);\n",
    "\n",
    "def get_PDPvalues(col_name, data, model, grid_resolution = 100):\n",
    "    Xnew = data.copy()\n",
    "    sequence = np.linspace(np.min(data[col_name]), np.max(data[col_name]), grid_resolution)\n",
    "    Y_pdp = []\n",
    "    for each in sequence:\n",
    "        Xnew[col_name] = each\n",
    "        Y_temp = model.predict(Xnew)\n",
    "        Y_pdp.append(np.mean(Y_temp))\n",
    "    return pd.DataFrame({col_name: sequence, 'PDs': Y_pdp})\n",
    "\n",
    "def plot_PDP(col_name, data, model):\n",
    "    df = get_PDPvalues(col_name, data, model)\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.rcParams[\"figure.figsize\"] = (6,5)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(data[col_name], np.zeros(data[col_name].shape)+min(df['PDs'])-1, 'k|', ms=15)  # rug plot\n",
    "    ax.plot(df[col_name], df['PDs'], lw = 2)\n",
    "    ax.set_ylabel('Partial Dependence')\n",
    "    return ax\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8)) = plt.subplots(4, 2, figsize=(18, 20))\n",
    "\n",
    "df = get_PDPvalues('CreditAmount', X, model)\n",
    "ax1.plot(X['CreditAmount'], np.zeros(X['CreditAmount'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax1.plot(df['CreditAmount'], df['PDs'], lw = 2)\n",
    "ax1.set_ylabel('Partial Dependence')\n",
    "\n",
    "\n",
    "\n",
    "df = get_PDPvalues('CreditDuration', X, model)\n",
    "ax2.plot(X['CreditDuration'], np.zeros(X['CreditDuration'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax2.plot(df['CreditDuration'], df['PDs'], lw = 2)\n",
    "ax2.set_ylabel('CreditDuration')\n",
    "\n",
    "\n",
    "\n",
    "df = get_PDPvalues('InstallmentRate', X, model)\n",
    "ax3.plot(X['InstallmentRate'], np.zeros(X['InstallmentRate'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax3.plot(df['InstallmentRate'], df['PDs'], lw = 2)\n",
    "ax3_twin=ax3.twinx()\n",
    "\n",
    "sns.distplot(X['InstallmentRate'], hist=False,\n",
    "             bins=int(180/5), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'}, ax=ax3_twin)\n",
    "ax3.set_ylabel('InstallmentRate')\n",
    "ax3_twin.set_ylabel(\"InstallmentRate density\",color=\"red\",fontsize=14)\n",
    "ax3.set_ylabel('InstallmentRate')\n",
    "\n",
    "\n",
    "\n",
    "df = get_PDPvalues('Age', X, model)\n",
    "ax4.plot(X['Age'], np.zeros(X['Age'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax4.plot(df['Age'], df['PDs'], lw = 2)\n",
    "\n",
    "ax4_twin=ax4.twinx()\n",
    "\n",
    "sns.distplot(X['Age'], hist=False,\n",
    "             bins=int(180/5), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'}, ax=ax4_twin)\n",
    "ax4.set_ylabel('Age')\n",
    "ax4_twin.set_ylabel(\"Age density\",color=\"red\",fontsize=14)\n",
    "\n",
    "\n",
    "\n",
    "df = get_PDPvalues('NumberOfCredits', X, model)\n",
    "ax5.plot(X['NumberOfCredits'], np.zeros(X['NumberOfCredits'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax5.plot(df['NumberOfCredits'], df['PDs'], lw = 2)\n",
    "ax5_twin=ax5.twinx()\n",
    "sns.distplot(X['NumberOfCredits'], hist=False,\n",
    "             bins=int(180/5), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'}, ax=ax5_twin)\n",
    "ax5_twin.set_ylabel(\"NumberOfCredits density\",color=\"red\",fontsize=14)\n",
    "ax5.set_ylabel('NumberOfCredits')\n",
    "\n",
    "df = get_PDPvalues('CreditHistory', X, model)\n",
    "ax6.plot(X['CreditHistory'], np.zeros(X['CreditHistory'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax6.plot(df['CreditHistory'], df['CreditHistory'], lw = 2)\n",
    "ax6.set_ylabel('CreditHistory')\n",
    "\n",
    "df = get_PDPvalues('MonthRefunding', X, model)\n",
    "ax7.plot(X['MonthRefunding'], np.zeros(X['MonthRefunding'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax7.plot(df['MonthRefunding'], df['MonthRefunding'], lw = 2)\n",
    "ax7.set_ylabel('MonthRefunding')\n",
    "\n",
    "df = get_PDPvalues('Group', X, model)\n",
    "ax8.plot(X['Group'], np.zeros(X['Group'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax8.plot(df['Group'], df['PDs'], lw = 2)\n",
    "ax8.set_ylabel('Group');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try with ALE \n",
    "\n",
    "from alibi.explainers import ALE, plot_ale\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8)) = plt.subplots(4, 2, figsize=(18, 20))\n",
    "\n",
    "ale = ALE(model.predict, feature_names=X_train.columns, target_names=[\"CreditRisk (y)\"])\n",
    "ale_exp = ale.explain(np.array(X_train))\n",
    "\n",
    "plot_ale(ale_exp, features=[\"CreditDuration\"], ax=ax1)\n",
    "plot_ale(ale_exp, features=[\"CreditAmount\"], ax=ax2)\n",
    "plot_ale(ale_exp, features=[\"InstallmentRate\"], ax=ax3)\n",
    "plot_ale(ale_exp, features=[\"Age\"], ax=ax4)\n",
    "plot_ale(ale_exp, features=[\"NumberOfCredits\"], ax=ax5)\n",
    "plot_ale(ale_exp, features=[\"MonthRefunding\"], ax=ax6)\n",
    "plot_ale(ale_exp, features=[\"Gender\"], ax=ax7)\n",
    "plot_ale(ale_exp, features=[\"Group\"], ax=ax8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let's try with ICE\n",
    "\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "features = [0, 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 18))\n",
    "\n",
    "plot_partial_dependence(model,       \n",
    "                                   features=[i for i in range(len(X_train.columns))], # column numbers of plots we want to show\n",
    "                                   X=X,            # raw predictors data.\n",
    "                                   feature_names=[i for i in X_train.columns], # labels on graphs\n",
    "                                   grid_resolution=10, kind=\"individual\", ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.LinearExplainer(model, X_train)\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Make plot. Index of [1] is explained in text below.\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "df = pd.read_excel(\"data_project.xlsx\")\n",
    "\n",
    "with open('config.json', \"r\") as f:\n",
    "    data = f.read()\n",
    "  \n",
    "      \n",
    "# reconstructing the data as a dictionary\n",
    "js = json.loads(data)\n",
    "\n",
    "#On remplace les données codées par du texte\n",
    "\n",
    "df = df.replace(js)\n",
    "\n",
    "Oe = OneHotEncoder()\n",
    "le = OrdinalEncoder()\n",
    "\n",
    "to_encode = ['CreditHistory', 'EmploymentDuration', 'Housing', 'Purpose', 'Savings']\n",
    "\n",
    "df[\"MonthRefunding\"] = df[\"CreditAmount\"]/df[\"CreditDuration\"]\n",
    "\n",
    "for col in to_encode:\n",
    "    df[col] = le.fit_transform(np.array(df[col]).reshape(-1, 1))\n",
    "\n",
    "X, y = df.drop([\"CreditRisk (y)\", \"y_hat\"], axis=1), df[\"CreditRisk (y)\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"The accuracy of the model is {:.2f}\".format(model.score(X_test, y_test)))\n",
    "print(\"The precision of the model is {:.2f}\".format(precision_score(y_pred, y_test)))\n",
    "print(\"The recall of the model is {:.2f}\".format(recall_score(y_pred, y_test)))\n",
    "print(\"The f1-score of the model is {:.2f}\".format(f1_score(y_pred, y_test)))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "# predict probabilities\n",
    "lr_probs = model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"ROC Curve of the Random Forest model\", fontsize=15)\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, label='Model', color=\"blue\")\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn.inspection import partial_dependence\n",
    "\n",
    "X, y = df.drop([\"CreditRisk (y)\", \"y_hat\"], axis=1), df[\"CreditRisk (y)\"]\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The partial_dependence function returns the dependencies and the grid\n",
    "PDs, grid = partial_dependence(model, X, features = ['CreditDuration'], percentiles = [0,1])\n",
    "\n",
    "#The plot_partial_dependence function returns a plot, but can also be unpacked into dependencies and grids\n",
    "#plot_partial_dependence(model, X, features = ['CreditDuration'], percentiles = [0,1]);\n",
    "\n",
    "def get_PDPvalues(col_name, data, model, grid_resolution = 100):\n",
    "    Xnew = data.copy()\n",
    "    sequence = np.linspace(np.min(data[col_name]), np.max(data[col_name]), grid_resolution)\n",
    "    Y_pdp = []\n",
    "    for each in sequence:\n",
    "        Xnew[col_name] = each\n",
    "        Y_temp = model.predict(Xnew)\n",
    "        Y_pdp.append(np.mean(Y_temp))\n",
    "    return pd.DataFrame({col_name: sequence, 'PDs': Y_pdp})\n",
    "\n",
    "def plot_PDP(col_name, data, model):\n",
    "    df = get_PDPvalues(col_name, data, model)\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.rcParams[\"figure.figsize\"] = (6,5)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(data[col_name], np.zeros(data[col_name].shape)+min(df['PDs'])-1, 'k|', ms=15)  # rug plot\n",
    "    ax.plot(df[col_name], df['PDs'], lw = 2)\n",
    "    ax.set_ylabel('Partial Dependence')\n",
    "    return ax\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8)) = plt.subplots(4, 2, figsize=(18, 20))\n",
    "\n",
    "df = get_PDPvalues('CreditAmount', X, model)\n",
    "ax1.plot(X['CreditAmount'], np.zeros(X['CreditAmount'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax1.plot(df['CreditAmount'], df['PDs'], lw = 2)\n",
    "ax1.set_ylabel('Partial Dependence')\n",
    "\n",
    "\n",
    "\n",
    "df = get_PDPvalues('CreditDuration', X, model)\n",
    "ax2.plot(X['CreditDuration'], np.zeros(X['CreditDuration'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax2.plot(df['CreditDuration'], df['PDs'], lw = 2)\n",
    "ax2.set_ylabel('CreditDuration')\n",
    "\n",
    "\n",
    "\n",
    "df = get_PDPvalues('InstallmentRate', X, model)\n",
    "ax3.plot(X['InstallmentRate'], np.zeros(X['InstallmentRate'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax3.plot(df['InstallmentRate'], df['PDs'], lw = 2)\n",
    "ax3_twin=ax3.twinx()\n",
    "\n",
    "sns.distplot(X['InstallmentRate'], hist=False,\n",
    "             bins=int(180/5), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'}, ax=ax3_twin)\n",
    "ax3.set_ylabel('InstallmentRate')\n",
    "ax3_twin.set_ylabel(\"InstallmentRate density\",color=\"red\",fontsize=14)\n",
    "ax3.set_ylabel('InstallmentRate')\n",
    "\n",
    "\n",
    "\n",
    "df = get_PDPvalues('Age', X, model)\n",
    "ax4.plot(X['Age'], np.zeros(X['Age'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax4.plot(df['Age'], df['PDs'], lw = 2)\n",
    "\n",
    "ax4_twin=ax4.twinx()\n",
    "\n",
    "sns.distplot(X['Age'], hist=False,\n",
    "             bins=int(180/5), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'}, ax=ax4_twin)\n",
    "ax4.set_ylabel('Age')\n",
    "ax4_twin.set_ylabel(\"Age density\",color=\"red\",fontsize=14)\n",
    "\n",
    "\n",
    "\n",
    "df = get_PDPvalues('NumberOfCredits', X, model)\n",
    "ax5.plot(X['NumberOfCredits'], np.zeros(X['NumberOfCredits'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax5.plot(df['NumberOfCredits'], df['PDs'], lw = 2)\n",
    "ax5_twin=ax5.twinx()\n",
    "sns.distplot(X['NumberOfCredits'], hist=False,\n",
    "             bins=int(180/5), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'}, ax=ax5_twin)\n",
    "ax5_twin.set_ylabel(\"NumberOfCredits density\",color=\"red\",fontsize=14)\n",
    "ax5.set_ylabel('NumberOfCredits')\n",
    "\n",
    "df = get_PDPvalues('CreditHistory', X, model)\n",
    "ax6.plot(X['CreditHistory'], np.zeros(X['CreditHistory'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax6.plot(df['CreditHistory'], df['CreditHistory'], lw = 2)\n",
    "ax6.set_ylabel('CreditHistory')\n",
    "\n",
    "df = get_PDPvalues('MonthRefunding', X, model)\n",
    "ax7.plot(X['MonthRefunding'], np.zeros(X['MonthRefunding'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax7.plot(df['MonthRefunding'], df['MonthRefunding'], lw = 2)\n",
    "ax7.set_ylabel('MonthRefunding')\n",
    "\n",
    "df = get_PDPvalues('Group', X, model)\n",
    "ax8.plot(X['Group'], np.zeros(X['Group'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax8.plot(df['Group'], df['PDs'], lw = 2)\n",
    "ax8.set_ylabel('Group');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(model, X_train)\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Make plot. Index of [1] is explained in text below.\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BlackBox model, XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "df = pd.read_excel(\"data_project.xlsx\")\n",
    "\n",
    "with open('config.json', \"r\") as f:\n",
    "    data = f.read()\n",
    "  \n",
    "      \n",
    "# reconstructing the data as a dictionary\n",
    "js = json.loads(data)\n",
    "\n",
    "#On remplace les données codées par du texte\n",
    "\n",
    "df = df.replace(js)\n",
    "\n",
    "Oe = OneHotEncoder()\n",
    "le = OrdinalEncoder()\n",
    "\n",
    "to_encode = ['CreditHistory', 'EmploymentDuration', 'Housing', 'Purpose', 'Savings']\n",
    "\n",
    "df[\"MonthRefunding\"] = df[\"CreditAmount\"]/df[\"CreditDuration\"]\n",
    "\n",
    "for col in to_encode:\n",
    "    df[col] = le.fit_transform(np.array(df[col]).reshape(-1, 1))\n",
    "\n",
    "X, y = df.drop([\"CreditRisk (y)\", \"y_hat\"], axis=1), df[\"CreditRisk (y)\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#The partial_dependence function returns the dependencies and the grid\n",
    "PDs, grid = partial_dependence(model, X, features = ['CreditDuration'], percentiles = [0,1])\n",
    "\n",
    "#The plot_partial_dependence function returns a plot, but can also be unpacked into dependencies and grids\n",
    "#plot_partial_dependence(model, X, features = ['CreditDuration'], percentiles = [0,1]);\n",
    "\n",
    "def get_PDPvalues(col_name, data, model, grid_resolution = 100):\n",
    "    Xnew = data.copy()\n",
    "    sequence = np.linspace(np.min(data[col_name]), np.max(data[col_name]), grid_resolution)\n",
    "    Y_pdp = []\n",
    "    for each in sequence:\n",
    "        Xnew[col_name] = each\n",
    "        Y_temp = model.predict(Xnew)\n",
    "        Y_pdp.append(np.mean(Y_temp))\n",
    "    return pd.DataFrame({col_name: sequence, 'PDs': Y_pdp})\n",
    "\n",
    "def plot_PDP(col_name, data, model):\n",
    "    df = get_PDPvalues(col_name, data, model)\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.rcParams[\"figure.figsize\"] = (6,5)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(data[col_name], np.zeros(data[col_name].shape)+min(df['PDs'])-1, 'k|', ms=15)  # rug plot\n",
    "    ax.plot(df[col_name], df['PDs'], lw = 2)\n",
    "    ax.set_ylabel('Partial Dependence')\n",
    "    return ax\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8)) = plt.subplots(4, 2, figsize=(18, 20))\n",
    "\n",
    "df = get_PDPvalues('CreditAmount', X, model)\n",
    "ax1.plot(X['CreditAmount'], np.zeros(X['CreditAmount'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax1.plot(df['CreditAmount'], df['PDs'], lw = 2)\n",
    "ax1.set_ylabel('Partial Dependence')\n",
    "\n",
    "\n",
    "\n",
    "df = get_PDPvalues('CreditDuration', X, model)\n",
    "ax2.plot(X['CreditDuration'], np.zeros(X['CreditDuration'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax2.plot(df['CreditDuration'], df['PDs'], lw = 2)\n",
    "ax2.set_ylabel('CreditDuration')\n",
    "\n",
    "\n",
    "\n",
    "df = get_PDPvalues('InstallmentRate', X, model)\n",
    "ax3.plot(X['InstallmentRate'], np.zeros(X['InstallmentRate'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax3.plot(df['InstallmentRate'], df['PDs'], lw = 2)\n",
    "ax3_twin=ax3.twinx()\n",
    "\n",
    "sns.distplot(X['InstallmentRate'], hist=False,\n",
    "             bins=int(180/5), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'}, ax=ax3_twin)\n",
    "ax3.set_ylabel('InstallmentRate')\n",
    "ax3_twin.set_ylabel(\"InstallmentRate density\",color=\"red\",fontsize=14)\n",
    "ax3.set_ylabel('InstallmentRate')\n",
    "\n",
    "\n",
    "\n",
    "df = get_PDPvalues('Age', X, model)\n",
    "ax4.plot(X['Age'], np.zeros(X['Age'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax4.plot(df['Age'], df['PDs'], lw = 2)\n",
    "\n",
    "ax4_twin=ax4.twinx()\n",
    "\n",
    "sns.distplot(X['Age'], hist=False,\n",
    "             bins=int(180/5), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'}, ax=ax4_twin)\n",
    "ax4.set_ylabel('Age')\n",
    "ax4_twin.set_ylabel(\"Age density\",color=\"red\",fontsize=14)\n",
    "\n",
    "\n",
    "\n",
    "df = get_PDPvalues('NumberOfCredits', X, model)\n",
    "ax5.plot(X['NumberOfCredits'], np.zeros(X['NumberOfCredits'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax5.plot(df['NumberOfCredits'], df['PDs'], lw = 2)\n",
    "ax5_twin=ax5.twinx()\n",
    "sns.distplot(X['NumberOfCredits'], hist=False,\n",
    "             bins=int(180/5), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'}, ax=ax5_twin)\n",
    "ax5_twin.set_ylabel(\"NumberOfCredits density\",color=\"red\",fontsize=14)\n",
    "ax5.set_ylabel('NumberOfCredits')\n",
    "\n",
    "df = get_PDPvalues('CreditHistory', X, model)\n",
    "ax6.plot(X['CreditHistory'], np.zeros(X['CreditHistory'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax6.plot(df['CreditHistory'], df['CreditHistory'], lw = 2)\n",
    "ax6.set_ylabel('CreditHistory')\n",
    "\n",
    "df = get_PDPvalues('MonthRefunding', X, model)\n",
    "ax7.plot(X['MonthRefunding'], np.zeros(X['MonthRefunding'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax7.plot(df['MonthRefunding'], df['MonthRefunding'], lw = 2)\n",
    "ax7.set_ylabel('MonthRefunding')\n",
    "\n",
    "df = get_PDPvalues('Group', X, model)\n",
    "ax8.plot(X['Group'], np.zeros(X['Group'].shape)+min(df['PDs'])-1, 'k|', ms=15)\n",
    "ax8.plot(df['Group'], df['PDs'], lw = 2)\n",
    "ax8.set_ylabel('Group');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import ALE, plot_ale\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8)) = plt.subplots(4, 2, figsize=(18, 20))\n",
    "\n",
    "model.fit(X.values, y)\n",
    "\n",
    "ale = ALE(model.predict, feature_names=X.columns, target_names=[\"CreditRisk (y)\"])\n",
    "ale_exp = ale.explain(np.array(X.values))\n",
    "\n",
    "plot_ale(ale_exp, features=[\"CreditDuration\"], ax=ax1)\n",
    "plot_ale(ale_exp, features=[\"CreditAmount\"], ax=ax2)\n",
    "plot_ale(ale_exp, features=[\"InstallmentRate\"], ax=ax3)\n",
    "plot_ale(ale_exp, features=[\"Age\"], ax=ax4)\n",
    "plot_ale(ale_exp, features=[\"NumberOfCredits\"], ax=ax5)\n",
    "plot_ale(ale_exp, features=[\"MonthRefunding\"], ax=ax6)\n",
    "plot_ale(ale_exp, features=[\"Gender\"], ax=ax7)\n",
    "plot_ale(ale_exp, features=[\"Group\"], ax=ax8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 18))\n",
    "\n",
    "plot_partial_dependence(model,       \n",
    "                                   features=[i for i in range(len(X_train.columns))], # column numbers of plots we want to show\n",
    "                                   X=X,            # raw predictors data.\n",
    "                                   feature_names=[i for i in X_train.columns], # labels on graphs\n",
    "                                   grid_resolution=10, kind=\"individual\", ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import shap  # package used to calculate Shap values\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(model, X_train)\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Make plot. Index of [1] is explained in text below.\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"The accuracy of the model is {:.2f}\".format(model.score(X_test, y_test)))\n",
    "print(\"The precision of the model is {:.2f}\".format(precision_score(y_pred, y_test)))\n",
    "print(\"The recall of the model is {:.2f}\".format(recall_score(y_pred, y_test)))\n",
    "print(\"The f1-score of the model is {:.2f}\".format(f1_score(y_pred, y_test)))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "# predict probabilities\n",
    "lr_probs = model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"ROC Curve of the XGBOOST model\", fontsize=15)\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, label='Model', color=\"blue\")\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
